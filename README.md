# üöó Car Model Acceptance Prediction

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Scikit-Learn](https://img.shields.io/badge/Scikit_Learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)
[![Status](https://img.shields.io/badge/Status-Completed-success?style=for-the-badge)]()

Ce projet propose une analyse comparative de mod√®les d'apprentissage supervis√© pour √©valuer l'acceptabilit√© de v√©hicules (UCI Car Evaluation Dataset). L'√©tude confronte les **Arbres de D√©cision** classiques aux m√©thodes ensemblistes (**Random Forest** et **Gradient Boosting**) sur des t√¢ches de classification multiclasse et binaire.

## üìã Description du Projet

L'objectif est de pr√©dire la classe d'un v√©hicule (`unacc`, `acc`, `good`, `vgood`) ou de recommander son achat (`No`, `Yes`) en fonction de 6 caract√©ristiques : prix d'achat, co√ªt d'entretien, nombre de portes, capacit√©, taille du coffre et s√©curit√©.

### M√©thodologie
1.  **Pr√©traitement** : Encodage des variables ordinales (OrdinalEncoder) et gestion des classes d√©s√©quilibr√©es.
2.  **Mod√©lisation** :
    * *Decision Tree* (Baseline)
    * *Random Forest* (Bagging)
    * *Gradient Boosting* (Boosting)
3.  **Optimisation** : Recherche d'hyperparam√®tres pour maximiser le Rappel et l'Accuracy.

---

## üìä R√©sultats Cl√©s

### 1. Classification Multiclasse (4 cat√©gories)
Le **Gradient Boosting** s'impose comme le mod√®le le plus performant, surpassant l'arbre de d√©cision et le Random Forest, notamment sur la d√©tection des classes rares.

| Mod√®le | Accuracy Globale | Rappel (`vgood`) | Observation |
| :--- | :---: | :---: | :--- |
| **Decision Tree** | ~91.00% | 0.90 | Difficult√©s √† g√©n√©raliser sur les donn√©es complexes. |
| **Random Forest** | 98.00% | 0.90 | Tr√®s robuste, excellente pr√©cision globale. |
| **Gradient Boosting** | **98.84%** | **1.00** | **Meilleur Mod√®le**. Capture 100% des v√©hicules "Very Good". |

### 2. Classification Binaire (Recommandation : No / Yes)
Le d√©fi principal est le fort d√©s√©quilibre des classes (479 `No` vs 40 `Yes` dans le jeu de test).

* **Random Forest** : Le choix de la **s√©curit√©**.
    * **Pr√©cision : 1.00** (Aucun Faux Positif).
    * Si ce mod√®le recommande une voiture, elle est assur√©ment bonne.
* **Gradient Boosting** : Le choix de la **performance**.
    * **Accuracy : 95.18%**.
    * Meilleur compromis pour minimiser les Faux N√©gatifs (voitures rat√©es).
* **Decision Tree** :
    * Pr√©cision faible (**0.44**), g√©n√©rant trop de fausses recommandations.

---

## üõ†Ô∏è Installation et Utilisation

### Pr√©requis
* Python 3.x
* Biblioth√®ques : `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`

### Instructions
1.  **Cloner le d√©p√¥t** :
    ```bash
    git clone [https://github.com/votre-user/CarModelAcceptance-Ensemble.git](https://github.com/votre-user/CarModelAcceptance-Ensemble.git)
    cd CarModelAcceptance-Ensemble
    ```

2.  **Installer les d√©pendances** :
    ```bash
    pip install -r requirements.txt
    # Ou manuellement : pip install pandas scikit-learn seaborn matplotlib
    ```

3.  **Lancer l'analyse** :
    Ouvrez le notebook Jupyter ou ex√©cutez le script principal pour reproduire les entra√Ænements et visualiser les matrices de confusion.

---

## üìà Conclusion

Cette √©tude d√©montre la sup√©riorit√© des m√©thodes ensemblistes sur ce jeu de donn√©es :
* Utilisez le **Gradient Boosting** si la priorit√© est de ne manquer aucune opportunit√© (Rappel maximal).
* Utilisez le **Random Forest** si la priorit√© est d'√©viter absolument une mauvaise recommandation (Pr√©cision maximale).

---
*Projet r√©alis√© dans le cadre du module d'Apprentissage Supervis√©.*
